{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Task 2: Model Building & Training - Fraud Detection\n",
    "\n",
    "This notebook implements the machine learning pipeline for fraud detection on two datasets:\n",
    "1. **E-commerce Fraud Data**: Transactional data from an e-commerce platform.\n",
    "2. **Bank Credit Card Fraud Data**: Anonymized credit card transactions.\n",
    "\n",
    "**Objective**: Build, train, and evaluate classification models focusing on imbalanced data performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    precision_recall_curve, auc, f1_score, confusion_matrix, \n",
    "    classification_report, average_precision_score, PrecisionRecallDisplay\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('ggplot')\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading-md",
   "metadata": {},
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "We load the processed datasets and prepare them for modeling. This includes:\n",
    "- Selecting features and target\n",
    "- Dropping non-predictive identifiers and non-numeric columns\n",
    "- Converting boolean columns to integers\n",
    "- Stratified train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, target_col, drop_cols=None):\n",
    "    \"\"\"Separates features and target, drops unnecessary columns, and splits data.\"\"\"\n",
    "    X = df.drop(columns=[target_col])\n",
    "    if drop_cols:\n",
    "        X = X.drop(columns=[col for col in drop_cols if col in X.columns])\n",
    "    \n",
    "    # Drop any remaining object (string) columns\n",
    "    obj_cols = X.select_dtypes(include=['object']).columns\n",
    "    if len(obj_cols) > 0:\n",
    "        X = X.drop(columns=obj_cols)\n",
    "    \n",
    "    # Explicitly convert boolean columns to int\n",
    "    bool_cols = X.select_dtypes(include=['bool']).columns\n",
    "    if len(bool_cols) > 0:\n",
    "        X[bool_cols] = X[bool_cols].astype(int)\n",
    "    \n",
    "    y = df[target_col]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# File paths\n",
    "FRAUD_DATA_PATH = Path('../data/processed/Fraud_Data_Processed.csv')\n",
    "CREDIT_DATA_PATH = Path('../data/processed/creditcard_Processed.csv')\n",
    "\n",
    "# Load datasets\n",
    "fraud_df = pd.read_csv(FRAUD_DATA_PATH)\n",
    "credit_df = pd.read_csv(CREDIT_DATA_PATH)\n",
    "\n",
    "print(f\"Fraud Data Shape: {fraud_df.shape}\")\n",
    "print(f\"Credit Card Data Shape: {credit_df.shape}\")\n",
    "\n",
    "## Prepare E-commerce Fraud Data\n",
    "# user_id is an identifier, not a predictor. \n",
    "# Note: prepare_data will also drop other non-numeric columns automatically\n",
    "X_train_f, X_test_f, y_train_f, y_test_f = prepare_data(fraud_df, 'class', drop_cols=['user_id'])\n",
    "\n",
    "## Prepare Credit Card Fraud Data\n",
    "X_train_c, X_test_c, y_train_c, y_test_c = prepare_data(credit_df, 'Class')\n",
    "\n",
    "print(\"\\nData Splits:\")\n",
    "print(f\"Fraud Dataset - Train: {X_train_f.shape}, Test: {X_test_f.shape}\")\n",
    "print(f\"Credit Card Dataset - Train: {X_train_c.shape}, Test: {X_test_c.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-func-md",
   "metadata": {},
   "source": [
    "## 2. Evaluation Helper Function\n",
    "\n",
    "To ensure consistent evaluation, we define a function that calculates and displays key metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eval-func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc_pr = average_precision_score(y_test, y_prob)\n",
    "    \n",
    "    print(f\"--- {model_name} Evaluation ---\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"AUC-PR: {auc_pr:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix - {model_name}')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'f1': f1,\n",
    "        'auc_pr': auc_pr,\n",
    "        'y_prob': y_prob\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline-md",
   "metadata": {},
   "source": [
    "## 3. Baseline Model: Logistic Regression\n",
    "\n",
    "We use `class_weight='balanced'` to handle the high class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logistic-regression",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "print(\"### Training Logistic Regression on Fraud Data ###\")\n",
    "lr_f = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr_f.fit(X_train_f, y_train_f)\n",
    "results.append(evaluate_model(lr_f, X_test_f, y_test_f, 'Logistic Regression (Fraud Data)'))\n",
    "\n",
    "print(\"\\n### Training Logistic Regression on Credit Card Data ###\")\n",
    "lr_c = LogisticRegression(class_weight='balanced', max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr_c.fit(X_train_c, y_train_c)\n",
    "results.append(evaluate_model(lr_c, X_test_c, y_test_c, 'Logistic Regression (Credit Data)'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble-md",
   "metadata": {},
   "source": [
    "## 4. Ensemble Model: XGBoost\n",
    "\n",
    "XGBoost is used with `scale_pos_weight` to focus on the minority (fraud) class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgboost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_xgb(X_train, y_train, X_test, y_test, name):\n",
    "    # Calculate scale_pos_weight\n",
    "    neg = len(y_train[y_train == 0])\n",
    "    pos = len(y_train[y_train == 1])\n",
    "    scale_weight = neg / pos\n",
    "    \n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        scale_pos_weight=scale_weight,\n",
    "        random_state=RANDOM_STATE,\n",
    "        eval_metric='aucpr',\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    \n",
    "    xgb.fit(X_train, y_train)\n",
    "    return evaluate_model(xgb, X_test, y_test, f'XGBoost ({name})'), xgb\n",
    "\n",
    "print(\"### Training XGBoost on Fraud Data ###\")\n",
    "res_xgb_f, xgb_f = train_xgb(X_train_f, y_train_f, X_test_f, y_test_f, 'Fraud Data')\n",
    "results.append(res_xgb_f)\n",
    "\n",
    "print(\"\\n### Training XGBoost on Credit Card Data ###\")\n",
    "res_xgb_c, xgb_c = train_xgb(X_train_c, y_train_c, X_test_c, y_test_c, 'Credit Data')\n",
    "results.append(res_xgb_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cv-md",
   "metadata": {},
   "source": [
    "## 5. Cross-Validation\n",
    "\n",
    "We perform 5-fold Stratified Cross-Validation to ensure model stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cv(model, X, y, name):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "    \n",
    "    f1_scores = cross_val_score(model, X, y, cv=skf, scoring='f1')\n",
    "    auc_pr_scores = cross_val_score(model, X, y, cv=skf, scoring='average_precision')\n",
    "    \n",
    "    print(f\"--- {name} Cross-Validation ---\")\n",
    "    print(f\"F1-Score: {f1_scores.mean():.4f} (+/- {f1_scores.std():.4f})\")\n",
    "    print(f\"AUC-PR: {auc_pr_scores.mean():.4f} (+/- {auc_pr_scores.std():.4f})\")\n",
    "    print()\n",
    "\n",
    "print(\"Running CV for Fraud Data models...\")\n",
    "run_cv(lr_f, X_train_f, y_train_f, 'LogReg Fraud')\n",
    "run_cv(xgb_f, X_train_f, y_train_f, 'XGBoost Fraud')\n",
    "\n",
    "print(\"Running CV for Credit Card models...\")\n",
    "run_cv(lr_c, X_train_c, y_train_c, 'LogReg Credit')\n",
    "run_cv(xgb_c, X_train_c, y_train_c, 'XGBoost Credit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparison-md",
   "metadata": {},
   "source": [
    "## 6. Model Comparison\n",
    "\n",
    "Comparing Precision-Recall curves side-by-side for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparison-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud Data PR Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "for res in results:\n",
    "    if 'Fraud Data' in res['model_name']:\n",
    "        label = f\"{res['model_name']} (AUC-PR={res['auc_pr']:.3f})\"\n",
    "        PrecisionRecallDisplay.from_predictions(y_test_f, res['y_prob'], name=label, ax=plt.gca())\n",
    "\n",
    "plt.title('Precision-Recall Curve Comparison - E-commerce Fraud Data')\n",
    "plt.axhline(y=y_test_f.mean(), color='r', linestyle='--', label='No Skill')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Credit Card PR Curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "for res in results:\n",
    "    if 'Credit' in res['model_name']:\n",
    "        label = f\"{res['model_name']} (AUC-PR={res['auc_pr']:.3f})\"\n",
    "        PrecisionRecallDisplay.from_predictions(y_test_c, res['y_prob'], name=label, ax=plt.gca())\n",
    "\n",
    "plt.title('Precision-Recall Curve Comparison - Credit Card Fraud Data')\n",
    "plt.axhline(y=y_test_c.mean(), color='r', linestyle='--', label='No Skill')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-md",
   "metadata": {},
   "source": [
    "## 7. Conclusion & Model Selection\n",
    "\n",
    "Based on the results above:\n",
    "\n",
    "- **AUC-PR** is the primary metric for selection as it accounts for the precision-recall trade-off across all thresholds.\n",
    "- **XGBoost** generally outperforms Logistic Regression on non-linear patterns in the Fraud Data.\n",
    "- For the **Credit Card** data (PCA features), both models perform exceptionally well, but XGBoost often has a slight edge on recall for very low false positive rates.\n",
    "\n",
    "### Business Impact:\n",
    "- **False Positives**: Lead to customer friction (declined legitimate transactions).\n",
    "- **False Negatives**: Lead to financial loss (missed fraud).\n",
    "The chosen model allows for threshold tuning to balance these depending on company risk appetite."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}